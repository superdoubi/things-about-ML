#relief算法用于特征选择
import numpy as np
from random import randrange

#用于生成数据集
from sklearn.datasets import make_classification
from sklearn.preprocessing import normalize
 
#定义计算距离计算
def distanceNorm(Norm,D_value):
        # initialization

 
        # Norm for distance
        #距离绝对值再求和
        if Norm == '1':
                counter = np.absolute(D_value);
                counter = np.sum(counter);
        #先平方后求和再开方
        elif Norm == '2':
                counter = np.power(D_value,2);
                counter = np.sum(counter);
                counter = np.sqrt(counter);
        #绝对值后求最大值
        elif Norm == 'Infinity':
                counter = np.absolute(D_value);
                counter = np.max(counter);
        else:
                raise Exception('We will program this later......');
 
        return counter;
 
 
 
 
 
def fit(features,labels,iter_ratio):
        # initialization
        (n_samples,n_features) = np.shape(features);
        distance = np.zeros((n_samples,n_samples));
        weight = np.zeros(n_features);
 
 
        if iter_ratio >= 0.5:
                # compute distance
                for index_i in range(n_samples):
                        for index_j in range(index_i+1,n_samples):
                                D_value = features[index_i] - features[index_j];
                                distance[index_i,index_j] = distanceNorm('2',D_value);
                distance += distance.T;
        else:
                pass;
 
 
        # start iteration
        for iter_num in range(int(iter_ratio*n_samples)):
                # print iter_num;
                # initialization
                nearHit = list();
                nearMiss = list();
                distance_sort = list();
 
                # random extract a sample
                index_i = randrange(0,n_samples,1);
                self_features = features[index_i];
 
                # search for nearHit and nearMiss
                if iter_ratio >= 0.5:
                        distance[index_i,index_i] = np.max(distance[index_i]);		# filter self-distance 
                        for index in range(n_samples):
                                distance_sort.append([distance[index_i,index],index,labels[index]]);
                else:
                        # compute distance respectively
                        distance = np.zeros(n_samples);
                        for index_j in range(n_samples):
                                D_value = features[index_i] - features[index_j];
                                distance[index_j] = distanceNorm('2',D_value);
                        distance[index_i] = np.max(distance);		# filter self-distance 
                        for index in range(n_samples):
                                distance_sort.append([distance[index],index,labels[index]]);
                        distance_sort.sort(key = lambda x:x[0]);
                for index in range(n_samples):
                        if nearHit == [] and distance_sort[index][2] == labels[index_i]:
                                # nearHit = distance_sort[index][1];
                                nearHit = features[distance_sort[index][1]];
                        elif nearMiss == [] and distance_sort[index][2] != labels[index_i]:
                                # nearMiss = distance_sort[index][1]
                                nearMiss = features[distance_sort[index][1]];
                        elif nearHit != [] and nearMiss != []:
                                break;
                        else:
                                continue;
 
                # update weight
                weight = weight - np.power(self_features - nearHit,2) + np.power(self_features - nearMiss,2);
        
        print(weight/(iter_ratio*n_samples));
        return weight/(iter_ratio*n_samples);
